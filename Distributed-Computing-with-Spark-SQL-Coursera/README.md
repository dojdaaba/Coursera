# Distributed Computing with Spark SQL-Coursera with Brooke Wenig and Conor Murphy by JAFUNO Douba 

All my Databricks Notebook and Assignment for this course 

SKILLS YOU WILL ACQUIRE (COMPÉTENCES QUE VOUS ACQUERREZ)

Data Science
Apache Spark
SQL

## About this Specialisation
This course is for students with SQL experience and now want to take the next step in gaining familiarity with distributed computing using Spark. 
Students will gain an understanding of when to use Spark and how Spark as an engine uniquely combines Data and AI technologies at scale. 
The four modules build on one another and by the end of the course 
the student will understand: Spark architecture, Spark DataFrame, optimizing reading/writing data, and how to build a machine learning model. 
The first module will introduce Spark, including how Spark works with distributed computing and what are Spark Dataframes. 
Module 2 covers the core concepts of Spark such as storage vs. computing, caching, partitions and Spark UI. 
The third module looks at Engineering Data Pipelines covering connecting to databases, schemas and type, file formats and writing good data. 
The final module looks at the application of Spark with Machine Learning through the business use case, 
a short introduction to what machine learning is, building and applying models and a final course conclusion. 
By understanding when to use Spark, either scaling out when the model or data is too large to process on a single machine, 
or having a need to simply speed up to get faster results, students will hone their SQL skills and become a more adept Data Scientist.

- **Module1 Introduction to Spark **

In this module, you will be able to discuss the core concepts of distributed computing and be able to recognize when and where to apply them. 
You'll be able to identify the basic data structure of Apache Spark™, known as a DataFrame. 
You will be able to use the collaborative Databricks workspace and write SQL code that executes against a cluster of machines.
- **Module2 Spark Core Concepts**

In this module, you will be able to explain the core concepts of Spark, and increase 
query performance by caching your data and modifying Spark configurations. 
You will also be able to use the Spark UI to analyze performance and identify bottlenecks.

- **Module3 Engineering Data Pipelines**

In this module, you will be able to identify and discuss the general demands of data applications. 
You'll be able to access data in a variety of formats and compare and contrast the tradeoffs between these formats. 
You will explore and examine semi-structured JSON data, which is common in big data environments, schemas, and parallel data writes. 
You will be able to create an end-to-end pipeline that reads data, transforms it, and saves the result.


- **Module4 Machine Learning Applications of Spark**

In this module, you will be able to define the basics of machine learning and identify the difference between regression and classification problems. 
You will build a linear regression model and use it to make predictions using Spark SQL. 
You will also be able to describe how machine learning fits in with concepts you learned in this course and from the other courses in this series. 
And lastly, you will be able to explain how a machine learning model is trained.

